# ai_assistant.py
"""
Evgenich AI Assistant
=====================
Unified module that powers the conversational logic of the
r—é–º–æ—á–Ω–∞—è‚Äë–∫–≤–∞—Ä—Ç–∏—Ä–Ω–∏–∫ helper ¬´–ï–≤–≥–µ–Ω–∏—á¬ª.
"""

from __future__ import annotations
import logging
from typing import List, Dict, Any

import openai
from config import OPENAI_API_KEY
from knowledge_base import KNOWLEDGE_BASE_TEXT
from menu_nastoiki import MENU_DATA
from food_menu import FOOD_MENU_DATA

# OpenAI initialisation
openai.api_key = OPENAI_API_KEY
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s ‚Äî %(levelname)s ‚Äî %(name)s ‚Äî %(message)s",
)
logger = logging.getLogger("evgenich_ai")

# --- –ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –ü–û–ò–°–ö–ê ---
def _find_relevant_info(query: str, knowledge_base: str, drink_menu: list, food_menu: dict) -> str:
    """
    –ù–∞—Ö–æ–¥–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –∏ –º–µ–Ω—é –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –∏–∑ –∑–∞–ø—Ä–æ—Å–∞.
    –≠—Ç–æ –ø—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è RAG (Retrieval-Augmented Generation).
    """
    query_words = {word.lower() for word in query.split()}
    relevant_context = []

    # 1. –ü–æ–∏—Å–∫ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
    for line in knowledge_base.split('\n'):
        if any(word in line.lower() for word in query_words):
            relevant_context.append(line)

    # 2. –ü–æ–∏—Å–∫ –≤ –º–µ–Ω—é –Ω–∞—Å—Ç–æ–µ–∫
    for category in drink_menu:
        for item in category.get("items", []):
            item_text = f"{category['title']} - {item['name']}: {item.get('narrative_desc', '')}"
            if any(word in item_text.lower() for word in query_words):
                relevant_context.append(item_text)

    # 3. –ü–æ–∏—Å–∫ –≤ –º–µ–Ω—é –µ–¥—ã
    for category, items in food_menu.items():
        for item in items:
            item_text = f"{category} - {item['name']}: {item.get('narrative_desc', '')}"
            if any(word in item_text.lower() for word in query_words):
                relevant_context.append(item_text)

    if not relevant_context:
        return "–ù–∏—á–µ–≥–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –Ω–µ –Ω–∞—à–ª–æ—Å—å, –Ω–æ —è –≤—Å—ë —Ä–∞–≤–Ω–æ –ø–æ–ø—Ä–æ–±—É—é –ø–æ–º–æ—á—å."

    return "\n".join(relevant_context)


def _create_system_prompt(updates_string: str) -> str:
    """Compose the large system prompt that defines –ï–≤–≥–µ–Ω–∏—á‚Äôs persona."""
    return (
        "# –†–û–õ–¨\n"
        "–¢—ã ‚Äî ¬´–ï–≤–≥–µ–Ω–∏—á¬ª. –î—É—à–∞ —Ä—é–º–æ—á–Ω–æ–π-–∫–≤–∞—Ä—Ç–∏—Ä–Ω–∏–∫–∞. –¢–≤–æ–π –æ–±—Ä–∞–∑ ‚Äî —ç—Ç–æ –°–µ—Ä–≥–µ–π –ñ—É–∫–æ–≤ –∏–∑ ¬´–†—É–∫–∏ –í–≤–µ—Ä—Ö!¬ª –≤ –∞—Ç–º–æ—Å—Ñ–µ—Ä–µ 80‚Äë—Ö: —Å–≤–æ–π –ø–∞—Ä–µ–Ω—å, –∫–æ—Ç–æ—Ä—ã–π –≤—Å–µ–≥–¥–∞ —Ä–∞–¥ –≥–æ—Å—Ç—è–º.\n\n"
        "# –•–ê–†–ê–ö–¢–ï–†\n"
        "- –¢–µ–ø–ª—ã–π, –Ω–æ—Å—Ç–∞–ª—å–≥–∏—á–µ—Å–∫–∏–π —Ç–æ–Ω.\n"
        "- –†–∞–∑–≥–æ–≤–æ—Ä ¬´–ø–æ –¥—É—à–∞–º¬ª, –±–µ–∑ –ø–∞—Ñ–æ—Å–∞.\n"
        "- –û—Ç—Å—ã–ª–∫–∏ –∫ 80‚Äì90‚Äë–º, –∫–æ–º–º—É–Ω–∞–ª–∫–∞–º, —Å—Ç–∞—Ä—ã–º —Ñ–∏–ª—å–º–∞–º.\n\n"
        "# –ü–ê–ú–Ø–¢–¨ –ò –ö–û–ù–¢–ï–ö–°–¢\n"
        "–¢–µ–±–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—è—Ç –∫—Ä–∞—Ç–∫—É—é –≤—ã–∂–∏–º–∫—É –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞ –≤–æ–ø—Ä–æ—Å—É –≥–æ—Å—Ç—è. –û—Ç–≤–µ—á–∞–π, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –Ω–µ–π, –ø–µ—Ä–µ—Å–∫–∞–∑—ã–≤–∞—è —Ñ–∞–∫—Ç—ã —Å–≤–æ–∏–º–∏ —Å–ª–æ–≤–∞–º–∏.\n\n"
        "# –¢–ï–ö–£–©–ò–ï –î–ê–ù–ù–´–ï\n"
        f"–°–µ–≥–æ–¥–Ω—è—à–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ: {updates_string}\n"
        "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–ø–µ—Ü–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö –ø–æ–¥–∞–≤–∞–π –∫–∞–∫ —Å–µ–∫—Ä–µ—Ç –¥–ª—è —Å–≤–æ–∏—Ö. –ï—Å–ª–∏ —á–µ–≥–æ-—Ç–æ –Ω–µ—Ç, –≥–æ–≤–æ—Ä–∏ –º—è–≥–∫–æ: ¬´–†–∞–∑–æ–±—Ä–∞–ª–∏, –∫–∞–∫ –≥–æ—Ä—è—á–∏–µ –ø–∏—Ä–æ–∂–∫–∏¬ª.\n\n"
        "# –°–¢–ò–õ–¨ –û–¢–í–ï–¢–ê (–û–ß–ï–ù–¨ –í–ê–ñ–ù–û)\n"
        "1.  **–ö–†–ê–¢–ö–û–°–¢–¨:** –û—Ç–≤–µ—Ç ‚Äî 1-2 –∫–æ—Ä–æ—Ç–∫–∏—Ö, –¥—É—à–µ–≤–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.\n"
        "2.  **–û–ë–†–ê–©–ï–ù–ò–Ø:** –ß–µ—Ä–µ–¥—É–π: ¬´—Ç–æ–≤–∞—Ä–∏—â¬ª, ¬´–¥—Ä—É–∂–∏—â–µ¬ª, ¬´–º–∏–ª —á–µ–ª–æ–≤–µ–∫¬ª, ¬´–¥–æ—Ä–æ–≥–æ–π¬ª.\n"
        "3.  **–ë–ï–ó –ñ–ò–†–ù–û–ì–û –®–†–ò–§–¢–ê:** –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π `*—Ç–µ–∫—Å—Ç*`.\n"
        "4.  **–≠–ú–û–î–ó–ò:** –í –∫–æ–Ω—Ü–µ 1-2 —É–º–µ—Å—Ç–Ω—ã—Ö —Å–º–∞–π–ª–∏–∫–∞: ü•É, üëç, üé∂, ü§´, üòâ, üòÑ, üìç.\n"
        "5.  **–û–¢–°–¢–£–ü–´:** –ò—Å–ø–æ–ª—å–∑—É–π –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫.\n\n"
        "# –°–¶–ï–ù–ê–†–ò–ò –û–¢–í–ï–¢–û–í\n"
        "1.  **–ì–æ—Å—Ç—å –∑–¥–æ—Ä–æ–≤–∞–µ—Ç—Å—è:** –û—Ç–≤–µ—Ç—å –¥—É—à–µ–≤–Ω–æ. –ü—Ä–∏–º–µ—Ä: ¬´–ù—É, –ø—Ä–æ—Ö–æ–¥–∏, —Ç–æ–≤–∞—Ä–∏—â. üòâ¬ª\n"
        "2.  **–ì–æ—Å—Ç—å —Ö–æ—á–µ—Ç –ó–ê–ë–†–û–ù–ò–†–û–í–ê–¢–¨ —Å—Ç–æ–ª:** –¢–≤–æ–π –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: `[START_BOOKING_FLOW]`\n"
        "3.  **–ì–æ—Å—Ç—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ –±–∞—Ä–µ, –º–µ–Ω—é:** –û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ, –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n"
        "4.  **–ì–æ—Å—Ç—å –ø–∏—à–µ—Ç –≥–ª—É–ø–æ—Å—Ç—å:** –û—Ç–≤–µ—á–∞–π —Å –¥–æ–±—Ä–æ–π –∏—Ä–æ–Ω–∏–µ–π."
    )

# --- PUBLIC API ---
def get_ai_recommendation(
    user_query: str,
    conversation_history: List[Dict[str, str]] | None = None,
    *,
    daily_updates: Dict[str, str] | None = None,
    model: str = "gpt-4o",
    temperature: float = 0.85,
    max_tokens: int = 200,
) -> str:
    """High‚Äëlevel entry point used by the Telegram layer."""
    
    logger.info("–ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å: %s", user_query)

    # 1. –ù–∞—Ö–æ–¥–∏–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é RAG
    relevant_context = _find_relevant_info(user_query, KNOWLEDGE_BASE_TEXT, MENU_DATA, FOOD_MENU_DATA)
    logger.info("–ù–∞–π–¥–µ–Ω–Ω—ã–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: %s", relevant_context)

    updates_string = f"–°–ø–µ—Ü–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å–µ–≥–æ–¥–Ω—è: {daily_updates.get('special', '–Ω–µ—Ç')}. –í —Å—Ç–æ–ø‚Äë–ª–∏—Å—Ç–µ: {daily_updates.get('stop-list', '–Ω–∏—á–µ–≥–æ')}" if daily_updates else "–Ω–µ—Ç –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"

    messages: list[dict[str, str]] = [
        {"role": "system", "content": _create_system_prompt(updates_string)}
    ]

    if conversation_history:
        messages.extend(conversation_history[-4:])

    # 2. –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è AI —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
    user_content = (
        f"–í–æ—Ç –º–æ–π –≤–æ–ø—Ä–æ—Å: '{user_query}'\n\n"
        f"–ê –≤–æ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, –∫–æ—Ç–æ—Ä—É—é —è –Ω–∞—à–µ–ª –¥–ª—è –æ—Ç–≤–µ—Ç–∞:\n---\n{relevant_context}\n---\n"
        "–ü–æ–º–æ–≥–∏ –º–Ω–µ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –¥—É—à–µ–≤–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ —Ç–≤–æ—ë–º —Å—Ç–∏–ª–µ."
    )
    messages.append({"role": "user", "content": user_content})

    try:
        logger.info("–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ OpenAI API‚Ä¶")
        completion = openai.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
        )
        response_text = completion.choices[0].message.content
        logger.info("–û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω —É—Å–ø–µ—à–Ω–æ.")
        return response_text.strip().strip('"')

    except Exception as exc:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenAI API: %s", exc)
        return "–¢–æ–≤–∞—Ä–∏—â, –º–æ–π –º—ã—Å–ª–∏—Ç–µ–ª—å–Ω—ã–π –∞–ø–ø–∞—Ä–∞—Ç –¥–∞–ª —Å–±–æ–π. –ü—Ä–æ–≤–æ–¥–∞, –≤–∏–¥–∞—Ç—å, –∑–∞–∏—Å–∫—Ä–∏–ª–∏. –ü–æ–ø—Ä–æ–±—É–π –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫–æ –º–Ω–µ —á—É—Ç—å –ø–æ–∑–∂–µ."
