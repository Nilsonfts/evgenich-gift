# /ai/smart_intent_detector.py
"""
–£–º–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä –Ω–∞–º–µ—Ä–µ–Ω–∏–π —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –æ–ø–µ—á–∞—Ç–æ–∫
–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
AI System v3.0
"""

import re
import logging
from typing import Tuple, Dict, List, Optional, NamedTuple
from difflib import SequenceMatcher

logger = logging.getLogger("evgenich_ai")


class DetectedIntent(NamedTuple):
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ –Ω–∞–º–µ—Ä–µ–Ω–∏—è"""
    name: str
    confidence: float
    entities: Dict
    priority: int


class SmartIntentDetector:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä –Ω–∞–º–µ—Ä–µ–Ω–∏–π —Å fuzzy matching"""
    
    def __init__(self):
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Å –≤–∞—Ä–∏–∞—Ü–∏—è–º–∏ –∏ –æ–ø–µ—á–∞—Ç–∫–∞–º–∏
        self.intent_patterns = {
            "booking": {
                "keywords": [
                    "–∑–∞–±—Ä–æ–Ω–∏—Ä–æ–≤–∞—Ç—å", "–∑–∞–±—Ä–æ–Ω–∏—Ä", "–±—Ä–æ–Ω—å", "–±—Ä–æ–Ω–∏—Ä–æ–≤–∞—Ç—å",
                    "—Å—Ç–æ–ª–∏–∫", "—Ä–µ–∑–µ—Ä–≤", "–∑–∞–∫–∞–∑–∞—Ç—å —Å—Ç–æ–ª", "–º–µ—Å—Ç–æ",
                    "–∑–∞–±—Ä–∞–Ω–∏—Ä–æ–≤–∞—Ç—å", "–∑–æ–±—Ä–æ–Ω–∏—Ä–æ–≤–∞—Ç—å", "–±—Ä–∞–Ω–∏—Ä–æ–≤–∞—Ç—å",  # –æ–ø–µ—á–∞—Ç–∫–∏
                    "–∑–∞–±—Ä–∞–Ω–∏—Ä–æ–≤", "–∑–æ–±—Ä–∞–Ω–∏—Ä–æ–≤", "–±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω",  # –µ—â—ë –æ–ø–µ—á–∞—Ç–∫–∏
                    "–∑–∞–ø–∏—Å—å", "–∑–∞–ø–∏—Å–∞—Ç—å—Å—è", "—Å–≤–æ–±–æ–¥–Ω", "–∑–∞–Ω—è—Ç—å",
                ],
                "phrases": [
                    "—Ö–æ—á—É —Å—Ç–æ–ª–∏–∫", "–º–æ–∂–Ω–æ —Å—Ç–æ–ª", "–µ—Å—Ç—å –º–µ—Å—Ç–∞", 
                    "—Å–≤–æ–±–æ–¥–Ω—ã–µ —Å—Ç–æ–ª—ã", "–∑–∞–±—Ä–æ–Ω–∏—Ç—å", "–±—Ä–æ–Ω–∏",
                    "—Ö–æ—á—É –∑–∞–±—Ä–æ–Ω–∏—Ä–æ–≤–∞—Ç—å", "–º–æ–∂–Ω–æ –∑–∞–±—Ä–æ–Ω–∏—Ä–æ–≤–∞—Ç—å",
                ],
                "priority": 1,
            },
            "address": {
                "keywords": [
                    "–∞–¥—Ä–µ—Å", "–≥–¥–µ", "–Ω–∞—Ö–æ–¥–∏—Ç–µ—Å—å", "–∫–∞–∫ –ø—Ä–æ–π—Ç–∏", 
                    "–∫–∞–∫ –¥–æ–±—Ä–∞—Ç—å—Å—è", "–¥–æ–π—Ç–∏", "–¥–æ–µ—Ö–∞—Ç—å", "–ª–æ–∫–∞—Ü–∏—è",
                    "–º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ", "–º–∞—Ä—à—Ä—É—Ç", "–º–µ—Ç—Ä–æ",
                ],
                "phrases": [
                    "–≥–¥–µ –≤—ã", "–∫–∞–∫ –≤–∞—Å –Ω–∞–π—Ç–∏", "–≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è",
                    "–∫–∞–∫ –∫ –≤–∞–º", "–≥–¥–µ –±–∞—Ä", "–∫–∞–∫–æ–π –∞–¥—Ä–µ—Å",
                ],
                "priority": 2,
            },
            "work_hours": {
                "keywords": [
                    "—Ä–∞–±–æ—Ç–∞–µ—Ç–µ", "–æ—Ç–∫—Ä—ã—Ç—ã", "–∑–∞–∫—Ä—ã—Ç—ã", "—á–∞—Å—ã", 
                    "—Ä–µ–∂–∏–º", "–≥—Ä–∞—Ñ–∏–∫", "–≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã", "—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ",
                    "–¥–æ —Å–∫–æ–ª—å–∫–∏", "—Å–æ —Å–∫–æ–ª—å–∫–∏",
                ],
                "phrases": [
                    "–≤–æ —Å–∫–æ–ª—å–∫–æ", "–¥–æ —Å–∫–æ–ª—å–∫–∏", "–∫–æ–≥–¥–∞ –æ—Ç–∫—Ä—ã—Ç",
                    "–∫–æ–≥–¥–∞ –∑–∞–∫—Ä—ã—Ç", "—Å–µ–π—á–∞—Å —Ä–∞–±–æ—Ç–∞–µ—Ç", "—Å–µ–π—á–∞—Å –æ—Ç–∫—Ä—ã—Ç",
                ],
                "priority": 2,
            },
            "karaoke": {
                "keywords": [
                    "–∫–∞—Ä–∞–æ–∫–µ", "–ø–µ—Ç—å", "—Å–ø–µ—Ç—å", "–ø–µ—Å–Ω–∏", "–º–∏–∫—Ä–æ—Ñ–æ–Ω",
                    "karaoke", "–∫–∞—Ä–æ–æ–∫–µ", "–∫–∞—Ä–æ–∫–µ",  # –æ–ø–µ—á–∞—Ç–∫–∏
                ],
                "phrases": [
                    "–º–æ–∂–Ω–æ –ø–æ–ø–µ—Ç—å", "–µ—Å—Ç—å –∫–∞—Ä–∞–æ–∫–µ", "–ø–æ—ë–º –ø–µ—Å–Ω–∏",
                    "—Ö–æ—á—É –ø–µ—Ç—å", "—Å–ø–µ—Ç—å –ø–µ—Å–Ω—é",
                ],
                "priority": 3,
            },
            "events": {
                "keywords": [
                    "–º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è", "—Å–æ–±—ã—Ç–∏—è", "–≤–µ—á–µ—Ä–∏–Ω–∫–∞", "–∫–æ–Ω—Ü–µ—Ä—Ç",
                    "–≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏–µ", "–∞—Ñ–∏—à–∞", "—á—Ç–æ –±—É–¥–µ—Ç", "–ø—Ä–æ–≥—Ä–∞–º–º–∞",
                    "—Ç—É—Å–æ–≤–∫–∞", "–¥–≤–∏–∂—É—Ö–∞",
                ],
                "phrases": [
                    "—á—Ç–æ —Å–µ–≥–æ–¥–Ω—è", "–∫–∞–∫–∏–µ –ø–ª–∞–Ω—ã", "—á—Ç–æ –Ω–∞–º–µ—á–∞–µ—Ç—Å—è",
                    "—á—Ç–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–≥–æ", "–∫–∞–∫–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞",
                ],
                "priority": 3,
            },
            "complaint": {
                "keywords": [
                    "–∂–∞–ª–æ–±–∞", "–ø–ª–æ—Ö–æ", "—É–∂–∞—Å–Ω–æ", "–æ—Ç–≤—Ä–∞—Ç–∏—Ç–µ–ª—å–Ω–æ",
                    "–Ω–µ–¥–æ–≤–æ–ª–µ–Ω", "—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω", "–æ–±–º–∞–Ω—É–ª–∏", "—Ö–∞–º—Å—Ç–≤–æ",
                    "–Ω–µ–≤–∫—É—Å–Ω–æ", "–¥–æ—Ä–æ–≥–æ", "–¥–æ–ª–≥–æ –∂–¥–∞–ª", "–Ω–∞—Ö–∞–º–∏–ª–∏",
                ],
                "phrases": [
                    "–Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å", "–ø–ª–æ—Ö–æ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ", 
                    "—Ö–æ—á—É –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å—Å—è", "–≤–µ—Ä–Ω–∏—Ç–µ –¥–µ–Ω—å–≥–∏",
                    "—ç—Ç–æ –±–µ–∑–æ–±—Ä–∞–∑–∏–µ", "–æ—á–µ–Ω—å –ø–ª–æ—Ö–æ",
                ],
                "priority": 0,  # –í—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç - –∂–∞–ª–æ–±—ã –≤–∞–∂–Ω—ã!
            },
            "gratitude": {
                "keywords": [
                    "—Å–ø–∞—Å–∏–±–æ", "–±–ª–∞–≥–æ–¥–∞—Ä—é", "—Å—É–ø–µ—Ä", "–∫–ª–∞—Å—Å", 
                    "–æ—Ç–ª–∏—á–Ω–æ", "–º–æ–ª–æ–¥–µ—Ü", "–∫—Ä—É—Ç–æ", "–æ–≥–æ–Ω—å",
                    "—Ç–æ–ø", "–±–æ–º–±–∞", "–∑–∞—á—ë—Ç",
                ],
                "phrases": [
                    "–±—ã–ª–æ –∑–¥–æ—Ä–æ–≤–æ", "–≤—Å—ë –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å", "–ø—Ä–∏–¥—ë–º –µ—â—ë",
                    "–æ—á–µ–Ω—å –≤–∫—É—Å–Ω–æ", "–æ—Ç–ª–∏—á–Ω—ã–π –≤–µ—á–µ—Ä",
                ],
                "priority": 4,
            },
            "greeting": {
                "keywords": [
                    "–ø—Ä–∏–≤–µ—Ç", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π", "–¥–æ–±—Ä—ã–π", "–ø—Ä–∏–≤–µ—Ç–∏–∫",
                    "—Ö–∞–π", "–∑–¥–∞—Ä–æ–≤–∞", "–π–æ", "—Ö–µ–ª–ª–æ", "–∫—É",
                ],
                "phrases": [
                    "–¥–æ–±—Ä–æ–µ —É—Ç—Ä–æ", "–¥–æ–±—Ä—ã–π –¥–µ–Ω—å", "–¥–æ–±—Ä—ã–π –≤–µ—á–µ—Ä",
                    "–¥–æ–±—Ä–æ–π –Ω–æ—á–∏",
                ],
                "priority": 5,
            },
            "price_inquiry": {
                "keywords": [
                    "—Ü–µ–Ω–∞", "—Å—Ç–æ–∏—Ç", "—Å—Ç–æ–∏–º–æ—Å—Ç—å", "–ø—Ä–∞–π—Å",
                    "–¥–æ—Ä–æ–≥–æ", "–¥—ë—à–µ–≤–æ", "–±—é–¥–∂–µ—Ç", "—á–µ–∫",
                ],
                "phrases": [
                    "—Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç", "–∫–∞–∫–∏–µ —Ü–µ–Ω—ã", "—Å—Ä–µ–¥–Ω–∏–π —á–µ–∫",
                    "–≤–æ —Å–∫–æ–ª—å–∫–æ –æ–±–æ–π–¥—ë—Ç—Å—è",
                ],
                "priority": 3,
            },
        }
        
        # –ü–æ—Ä–æ–≥ –¥–ª—è fuzzy matching (0.0 - 1.0)
        self.fuzzy_threshold = 0.75
    
    def _fuzzy_match(self, word: str, pattern: str) -> float:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ—Ö–æ–∂–µ—Å—Ç—å —Å–ª–æ–≤ (–¥–ª—è –æ–ø–µ—á–∞—Ç–æ–∫)"""
        return SequenceMatcher(None, word.lower(), pattern.lower()).ratio()
    
    def _check_fuzzy_keywords(self, text: str, keywords: List[str]) -> Tuple[bool, float]:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Å —É—á—ë—Ç–æ–º –æ–ø–µ—á–∞—Ç–æ–∫"""
        text_lower = text.lower()
        text_words = text_lower.split()
        
        best_score = 0.0
        found = False
        
        for keyword in keywords:
            # –¢–æ—á–Ω–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ –ø–æ–¥—Å—Ç—Ä–æ–∫–∏
            if keyword in text_lower:
                return True, 1.0
        
        # Fuzzy matching –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤
        for text_word in text_words:
            if len(text_word) < 4:  # –ö–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                continue
                
            for keyword in keywords:
                if len(keyword) < 4:
                    continue
                    
                score = self._fuzzy_match(text_word, keyword)
                if score > best_score:
                    best_score = score
                if score >= self.fuzzy_threshold:
                    found = True
                    logger.debug(f"Fuzzy match: '{text_word}' ‚âà '{keyword}' ({score:.2f})")
        
        return found, best_score
    
    def detect(self, message: str, context: List[Dict] = None) -> DetectedIntent:
        """
        –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–∞–º–µ—Ä–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        Args:
            message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            context: –ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            DetectedIntent —Å name, confidence, entities, priority
        """
        message_lower = message.lower().strip()
        
        # –ü—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        if not message_lower:
            return DetectedIntent("unknown", 0.0, {}, 99)
        
        results = []
        
        for intent_name, config in self.intent_patterns.items():
            keywords = config["keywords"]
            phrases = config.get("phrases", [])
            priority = config["priority"]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ—Ä–∞–∑—ã (—Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ–¥—Å—Ç—Ä–æ–∫–∏)
            phrase_match = any(phrase in message_lower for phrase in phrases)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Å fuzzy matching
            keyword_match, keyword_score = self._check_fuzzy_keywords(message_lower, keywords)
            
            if phrase_match:
                confidence = 0.95
            elif keyword_match:
                confidence = max(0.7, keyword_score)
            else:
                continue
            
            results.append({
                "intent": intent_name,
                "confidence": confidence,
                "priority": priority,
            })
        
        if not results:
            return DetectedIntent("general", 0.5, {}, 99)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É (–º–µ–Ω—å—à–µ = –≤–∞–∂–Ω–µ–µ), –ø–æ—Ç–æ–º –ø–æ confidence (–±–æ–ª—å—à–µ = –ª—É—á—à–µ)
        results.sort(key=lambda x: (x["priority"], -x["confidence"]))
        
        best = results[0]
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—É—â–Ω–æ—Å—Ç–∏
        entities = self._extract_entities(message_lower, best["intent"])
        
        logger.info(f"üéØ –ù–∞–º–µ—Ä–µ–Ω–∏–µ: {best['intent']} (conf: {best['confidence']:.2f}), entities: {entities}")
        
        return DetectedIntent(
            name=best["intent"],
            confidence=best["confidence"],
            entities=entities,
            priority=best["priority"]
        )
    
    def _extract_entities(self, message: str, intent: str) -> Dict:
        """–ò–∑–≤–ª–µ—á—å —Å—É—â–Ω–æ—Å—Ç–∏ –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        entities = {}
        
        # === –î–∞—Ç–∞ ===
        date_patterns = [
            (r"–Ω–∞ –∑–∞–≤—Ç—Ä–∞", "–∑–∞–≤—Ç—Ä–∞"),
            (r"–Ω–∞ —Å–µ–≥–æ–¥–Ω—è", "—Å–µ–≥–æ–¥–Ω—è"),
            (r"–Ω–∞ –ø–æ—Å–ª–µ–∑–∞–≤—Ç—Ä–∞", "–ø–æ—Å–ª–µ–∑–∞–≤—Ç—Ä–∞"),
            (r"–≤ –ø—è—Ç–Ω–∏—Ü—É", "–ø—è—Ç–Ω–∏—Ü–∞"),
            (r"–≤ —Å—É–±–±–æ—Ç—É", "—Å—É–±–±–æ—Ç–∞"),
            (r"–≤ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ", "–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ"),
            (r"(\d{1,2})[./](\d{1,2})", None),  # 15.01 –∏–ª–∏ 15/01
            (r"(\d{1,2})\s*(—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è)", None),
        ]
        
        for pattern, value in date_patterns:
            match = re.search(pattern, message)
            if match:
                entities["date"] = value or match.group(0)
                break
        
        # === –í—Ä–µ–º—è ===
        time_patterns = [
            r"–≤\s*(\d{1,2})[:\s]?(\d{2})?",
            r"–Ω–∞\s*(\d{1,2})[:\s]?(\d{2})?(?:\s*—á–∞—Å)?",
            r"–∫\s*(\d{1,2})[:\s]?(\d{2})?",
            r"(\d{1,2})[:\s](\d{2})",
        ]
        
        for pattern in time_patterns:
            match = re.search(pattern, message)
            if match:
                hour = match.group(1)
                minute = match.group(2) or "00"
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –≤—Ä–µ–º—è
                if int(hour) <= 24:
                    entities["time"] = f"{hour}:{minute}"
                    break
        
        # === –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª—é–¥–µ–π ===
        people_patterns = [
            (r"–Ω–∞\s*(\d+)\s*(?:—á–µ–ª–æ–≤–µ–∫|–ø–µ—Ä—Å–æ–Ω|–≥–æ—Å—Ç|—á–µ–ª)", lambda m: int(m.group(1))),
            (r"(\d+)\s*(?:—á–µ–ª–æ–≤–µ–∫|–ø–µ—Ä—Å–æ–Ω|–≥–æ—Å—Ç|—á–µ–ª)", lambda m: int(m.group(1))),
            (r"–Ω–∞—Å\s*(\d+)", lambda m: int(m.group(1))),
            (r"–±—É–¥–µ—Ç\s*(\d+)", lambda m: int(m.group(1))),
            (r"–∫–æ–º–ø–∞–Ω–∏—è\s*(\d+)", lambda m: int(m.group(1))),
            (r"–≤–¥–≤–æ—ë–º|–≤–¥–≤–æ–µ–º", lambda m: 2),
            (r"–≤—Ç—Ä–æ—ë–º|–≤—Ç—Ä–æ–µ–º", lambda m: 3),
            (r"–≤—á–µ—Ç–≤–µ—Ä–æ–º", lambda m: 4),
            (r"–≤–ø—è—Ç–µ—Ä–æ–º", lambda m: 5),
            (r"–≤—à–µ—Å—Ç–µ—Ä–æ–º", lambda m: 6),
        ]
        
        for pattern, extractor in people_patterns:
            match = re.search(pattern, message)
            if match:
                try:
                    entities["people_count"] = extractor(match)
                    break
                except:
                    pass
        
        # === –ë–∞—Ä ===
        if any(word in message for word in ["–Ω–µ–≤—Å–∫–∏–π", "–Ω–µ–≤—Å–∫–æ–≥–æ", "–º–∞—è–∫–æ–≤—Å–∫–∞—è", "–Ω–∞ 53", "53"]):
            entities["bar"] = "nevsky"
        elif any(word in message for word in ["—Ä—É–±–∏–Ω—à—Ç–µ–π–Ω–∞", "—Ä—É–±–∏–Ω–∞", "–Ω–∞ 9", " 9"]):
            entities["bar"] = "rubinshteina"
        
        # === –ù–∞–ø–∏—Ç–∫–∏ (–¥–ª—è –º–µ–Ω—é) ===
        drinks = ["—Ö—É–±–∞", "–ø–ª–æ–º–±–∏—Ä", "—Ñ–∏—Å—Ç–∞—à–∫", "–∫–ª—é–∫–≤", "–æ–±–ª–µ–ø–∏—Ö", "–ª–∏–º–æ–Ω—á–µ–ª–ª–æ", "—Ç–∞—ë–∂–Ω", "–∫–µ–¥—Ä–æ–≤"]
        for drink in drinks:
            if drink in message:
                entities["drink_mentioned"] = drink
                break
        
        return entities
    
    def get_supported_intents(self) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö –Ω–∞–º–µ—Ä–µ–Ω–∏–π"""
        return list(self.intent_patterns.keys())


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
smart_detector = SmartIntentDetector()
